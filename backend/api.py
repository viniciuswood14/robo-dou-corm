from fastapi import FastAPI, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Set, Dict, Any
from datetime import datetime
import os, io, zipfile, json, re
from urllib.parse import urljoin
import asyncio

import httpx
from bs4 import BeautifulSoup

# IA / Gemini
import google.generativeai as genai

# =====================================================================================
# Rob√¥ DOU API - vers√£o 13.9.4
#
# Diferen√ßas principais:
# - parse_mpo_budget_table() atualizado com regex tolerante
#   (√ìRG√ÉO SUPERIOR, UNIDADE OR√áAMENT√ÅRIA, UG, etc),
#   detecta blocos (ACR√âSCIMO)/(REDU√á√ÉO) mesmo sem o prefixo "PROGRAMA DE TRABALHO",
#   captura totais "TOTAL - FISCAL" / "TOTAL - GERAL",
#   agrupa por UO (52131, 52931, etc.) e monta texto WhatsApp com valores üí∏.
#
# - process_grouped_materia() chama parse_mpo_budget_table() sempre que for ato MPO
#   de LME / Fonte / Cr√©dito / GND e houver c√≥digos de Marinha.
#
# - Rotas /processar-inlabs e /processar-inlabs-ia mantidas.
# =====================================================================================

app = FastAPI(
    title="Rob√¥ DOU API (INLABS XML) - v13.9.4 (MPO parser valores Marinha)"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =====================================================================================
# CONFIG
# =====================================================================================

try:
    with open("config.json", "r", encoding="utf-8") as f:
        config = json.load(f)
except FileNotFoundError:
    raise RuntimeError("Erro: Arquivo 'config.json' n√£o encontrado.")
except json.JSONDecodeError:
    raise RuntimeError("Erro: Falha ao decodificar 'config.json'. Verifique a sintaxe.")

# Credenciais / URLs InLabs
INLABS_BASE = os.getenv(
    "INLABS_BASE", config.get("INLABS_BASE", "https://inlabs.in.gov.br")
)
INLABS_LOGIN_URL = os.getenv(
    "INLABS_LOGIN_URL", config.get("INLABS_LOGIN_URL", f"{INLABS_BASE}/login")
)
INLABS_USER = os.getenv("INLABS_USER", config.get("INLABS_USER", None))
INLABS_PASS = os.getenv("INLABS_PASS", config.get("INLABS_PASS", None))

# Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", config.get("GEMINI_API_KEY", None))
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Constantes auxiliares (templates e listas de palavras-chave)
TEMPLATE_LME = config.get("TEMPLATE_LME", "")
TEMPLATE_FONTE = config.get("TEMPLATE_FONTE", "")
TEMPLATE_CREDITO = config.get("TEMPLATE_CREDITO", "")
ANNOTATION_POSITIVE_GENERIC = config.get("ANNOTATION_POSITIVE_GENERIC", "")
ANNOTATION_NEGATIVE = config.get("ANNOTATION_NEGATIVE", "")

MPO_NAVY_TAGS = config.get("MPO_NAVY_TAGS", {})  # c√≥digos UO -> nome
KEYWORDS_DIRECT_INTEREST_S1 = config.get("KEYWORDS_DIRECT_INTEREST_S1", [])
BUDGET_KEYWORDS_S1 = config.get("BUDGET_KEYWORDS_S1", [])
MPO_ORG_STRING = config.get(
    "MPO_ORG_STRING", "minist√©rio do planejamento e or√ßamento"
)
PERSONNEL_ACTION_VERBS = config.get("PERSONNEL_ACTION_VERBS", [])
TERMS_AND_ACRONYMS_S2 = config.get("TERMS_AND_ACRONYMS_S2", [])
NAMES_TO_TRACK = sorted(
    list(set(config.get("NAMES_TO_TRACK", []))), key=str.lower
)

# PROMPTS IA
GEMINI_MASTER_PROMPT = """
Voc√™ √© um analista de or√ßamento e finan√ßas do Comando da Marinha do Brasil, especialista em legisla√ß√£o e defesa.
Sua tarefa √© ler a publica√ß√£o do Di√°rio Oficial da Uni√£o (DOU) abaixo e escrever uma √∫nica frase curta (m√°ximo 2 linhas) para um relat√≥rio de WhatsApp, focando exclusivamente no impacto para a Marinha do Brasil (MB).

Crit√©rios de An√°lise:
1.  Se for ato or√ßament√°rio (MPO/Fazenda), foque no impacto: √â cr√©dito, LME, fontes? Afeta UGs da Marinha ("52131": "Comando da Marinha",
    "52133": "Secretaria da Comiss√£o Interministerial para os Recursos do Mar",
    "52232": "Caixa de Constru√ß√µes de Casas para o Pessoal da Marinha - CCCPM",
    "52233": "Amaz√¥nia Azul Tecnologias de Defesa S.A. - AMAZUL",
    "52931": "Fundo Naval",
    "52932": "Fundo de Desenvolvimento do Ensino Profissional Mar√≠timo",
    "52000": "Minist√©rio da Defesa")?
2.  Se for ato normativo (Decreto, Portaria), qual a a√ß√£o ou responsabilidade criada para a Marinha/Autoridade Mar√≠tima?
3.  Se for ato de pessoal (Se√ß√£o 2), quem √© a pessoa e qual a a√ß√£o (nomea√ß√£o, exonera√ß√£o, viagem)?
4.  Se a men√ß√£o for trivial ou sem impacto direto (ex: 'Minist√©rio da Defesa' apenas listado numa reuni√£o, ou 'Marinha' no nome de uma empresa privada), responda APENAS: "Sem impacto direto."

Responda s√≥ a frase final, sem rodeio adicional.

TEXTO DA PUBLICA√á√ÉO:
"""

GEMINI_MPO_PROMPT = """
Voc√™ √© analista or√ßament√°rio da Marinha do Brasil. A publica√ß√£o abaixo √© do Minist√©rio do Planejamento e Or√ßamento (MPO) e J√Å FOI CLASSIFICADA como tendo impacto direto em dota√ß√µes ligadas √† Marinha (ex.: Fundo Naval, Comando da Marinha, etc.).

Sua tarefa √©:
1. Dizer claramente qual o efeito or√ßament√°rio: cr√©dito suplementar (refor√ßo de dota√ß√£o), altera√ß√£o de GND (reclassifica√ß√£o da natureza da despesa), mudan√ßa de fonte de recursos, antecipa√ß√£o/ajuste de LME etc.
2. Dizer quem √© afetado (Ex.: Comando da Marinha, Fundo Naval, Defesa/52000).
3. Se houver refor√ßo de dota√ß√£o ou acr√©scimo, deixe isso claro como positivo. Se houver cancelamento/redu√ß√£o, diga isso tamb√©m.
4. Entregar apenas UMA frase curta (m√°ximo 2 linhas) para WhatsApp.

Voc√™ N√ÉO pode responder "Sem impacto direto", porque esta portaria J√Å foi marcada como relevante para a MB.

TEXTO DA PUBLICA√á√ÉO:
"""

# =====================================================================================
# MODELOS Pydantic
# =====================================================================================

class Publicacao(BaseModel):
    organ: Optional[str] = None
    type: Optional[str] = None
    summary: Optional[str] = None
    raw: Optional[str] = None
    relevance_reason: Optional[str] = None
    section: Optional[str] = None
    clean_text: Optional[str] = None
    is_mpo_navy_hit: bool = False  # chave pro prompt da IA


class ProcessResponse(BaseModel):
    date: str
    count: int
    publications: List[Publicacao]
    whatsapp_text: str

# =====================================================================================
# HELPERS GERAIS
# =====================================================================================

_ws = re.compile(r"\s+")
def norm(s: Optional[str]) -> str:
    if not s:
        return ""
    return _ws.sub(" ", s).strip()

def monta_whatsapp(pubs: List[Publicacao], when: str) -> str:
    meses_pt = {
        1: "JAN", 2: "FEV", 3: "MAR", 4: "ABR",
        5: "MAI", 6: "JUN", 7: "JUL", 8: "AGO",
        9: "SET", 10: "OUT", 11: "NOV", 12: "DEZ"
    }
    try:
        dt = datetime.fromisoformat(when)
        dd = f"{dt.day:02d}{meses_pt.get(dt.month, '')}"
    except Exception:
        dd = when

    lines = []
    lines.append("Bom dia, senhores!")
    lines.append("")
    lines.append(f"PTC as seguintes publica√ß√µes de interesse no DOU de {dd}:")
    lines.append("")

    # agrupar publica√ß√µes por se√ß√£o (DO1, DO2...)
    pubs_by_section: Dict[str, List[Publicacao]] = {}
    for p in pubs:
        sec = p.section or "DOU"
        pubs_by_section.setdefault(sec, []).append(p)

    if not pubs:
        lines.append("‚Äî Sem ocorr√™ncias para os crit√©rios informados ‚Äî")
        return "\n".join(lines)

    for section_name in sorted(pubs_by_section.keys()):
        subseq = pubs_by_section[section_name]
        if not subseq:
            continue

        lines.append(f"üî∞ {section_name.replace('DO', 'Se√ß√£o ')}")
        lines.append("")

        for p in subseq:
            lines.append(f"‚ñ∂Ô∏è {p.organ or '√ìrg√£o'}")
            lines.append(f"üìå {p.type or 'Ato/Portaria'}")
            if p.summary:
                lines.append(p.summary)

            reason = p.relevance_reason or "Para conhecimento."
            prefix = "‚öì"

            # Se a IA disser que errou, a gente marca com ‚ö†Ô∏è
            if (
                reason.startswith("Erro na an√°lise de IA:")
                or reason.startswith("Erro GRAVE")
                or reason.startswith("‚ö†Ô∏è")
            ):
                prefix = "‚ö†Ô∏è Erro IA:"
                reason = (
                    reason.replace("Erro na an√°lise de IA:", "")
                    .replace("Erro GRAVE na an√°lise de IA:", "")
                    .replace("‚ö†Ô∏è IA ignorou impacto MPO:", "")
                    .strip()
                )

            if "\n" in reason:
                lines.append(f"{prefix}\n{reason}")
            else:
                lines.append(f"{prefix} {reason}")

            lines.append("")

    return "\n".join(lines)

# =====================================================================================
# PARSER MPO (tabelas de suplementa√ß√£o / redu√ß√£o / totais por UO)
# =====================================================================================

MB_UOS = {
    "52131": "Comando da Marinha",
    "52133": "Secretaria da Comiss√£o Interministerial para os Recursos do Mar",
    "52232": "Caixa de Constru√ß√µes de Casas para o Pessoal da Marinha - CCCPM",
    "52233": "Amaz√¥nia Azul Tecnologias de Defesa S.A. - AMAZUL",
    "52931": "Fundo Naval",
    "52932": "Fundo de Desenvolvimento do Ensino Profissional Mar√≠timo",
    "52000": "Minist√©rio da Defesa",  # Defesa inteira
}

def _clean_text_local(t: str) -> str:
    if t is None:
        return ""
    return re.sub(r"\s+", " ", t).strip()

def _parse_money(raw: str) -> int:
    raw = _clean_text_local(raw)
    if not raw:
        return 0
    raw = raw.replace(".", "").replace(",", "")
    m = re.findall(r"\d+", raw)
    if not m:
        return 0
    try:
        return int("".join(m))
    except:
        return 0
def parse_mpo_budget_table(full_text_content: str) -> str:
    """
    Extrai dados or√ßament√°rios das tabelas MPO (inclusive dentro de CDATA),
    filtra apenas blocos ligados ao Minist√©rio da Defesa / UOs da Marinha
    e gera texto pronto pro WhatsApp.

    Melhorias:
    - Detecta quando √© portaria de altera√ß√£o de fonte/IRP (ex: Portaria SOF/MPO n¬∫ 402),
      e muda o tom da mensagem ("Altera√ß√£o de fonte de recurso...") em vez de
      "Suplementa√ß√£o/Redu√ß√£o".
    - Consolida a√ß√µes parecidas (evita duplicar 21GN / 21GN 0001).
    """

    # -------------------------------------------------
    # Helpers locais
    # -------------------------------------------------
    def _clean_text_local(t: str) -> str:
        if t is None:
            return ""
        return re.sub(r"\s+", " ", t).strip()

    def _parse_money(raw: str) -> int:
        raw = _clean_text_local(raw)
        if not raw:
            return 0
        raw = raw.replace(".", "").replace(",", "")
        m = re.findall(r"\d+", raw)
        if not m:
            return 0
        try:
            return int("".join(m))
        except:
            return 0

    def _canonicalize_action_code(raw_code: str) -> str:
        """
        Normaliza c√≥digo de a√ß√£o para agrupar variantes tipo:
        "6112 21GN" vs "6112 21GN 0001"
        -> mant√©m s√≥ os dois primeiros blocos num√©ricos/letras.
        """
        parts = raw_code.split()
        if len(parts) >= 2:
            # Ex: ["6112","21GN","0001"] -> "6112 21GN"
            return " ".join(parts[:2])
        return raw_code.strip()

    MB_UOS = {
        "52131": "Comando da Marinha",
        "52133": "Secretaria da Comiss√£o Interministerial para os Recursos do Mar",
        "52232": "Caixa de Constru√ß√µes de Casas para o Pessoal da Marinha - CCCPM",
        "52233": "Amaz√¥nia Azul Tecnologias de Defesa S.A. - AMAZUL",
        "52931": "Fundo Naval",
        "52932": "Fundo de Desenvolvimento do Ensino Profissional Mar√≠timo",
        "52000": "Minist√©rio da Defesa",  # n√≠vel minist√©rio
    }

    ORGAO_REGEX = re.compile(
        r"√ìRG√ÉO(?:\s+\w+)?\s*:\s*(\d+)\s*-\s*(.+)",
        flags=re.IGNORECASE
    )
    UO_REGEX = re.compile(
        r"(UNIDADE(?:\s+\w+)?|UNIDADE\s+OR√áAMENT√ÅRIA|UNIDADE\s+ORCAMENTARIA|UG)\s*:\s*(\d+)\s*-\s*(.+)",
        flags=re.IGNORECASE,
    )
    BLOCO_TIPO_REGEX = re.compile(
        r"\(\s*(ACR√âSCIMO|ACRESCIMO|REDU√á√ÉO|REDUCAO)\s*\)",
        flags=re.IGNORECASE
    )
    TOTAL_REGEX = re.compile(
        r"TOTAL\s*-\s*(FISCAL|SEGURIDADE|GERAL)",
        flags=re.IGNORECASE
    )

    # -------------------------------------------------
    # 1. Detectar se essa mat√©ria √© de altera√ß√£o de fonte / IRP
    #    (isso muda o texto que vamos montar no final)
    # -------------------------------------------------
    lower_all = full_text_content.lower()
    is_alteracao_fonte = any(
        kw in lower_all
        for kw in [
            "modifica fontes de recursos",
            "modifica fonte de recursos",
            "fonte de recurso",
            "fontes de recursos",
            "identificador de resultado prim√°rio",
            "identificador de resultado primario",
            "altera√ß√£o de fonte",
            "alteracao de fonte",
            "reclassifica√ß√£o de fonte",
            "reclassificacao de fonte",
        ]
    )

    # -------------------------------------------------
    # 2. Extrair TODOS os blocos CDATA (√© onde est√£o as tabelas MPO)
    # -------------------------------------------------
    cdata_blocks = re.findall(
        r"<!\[CDATA\[(.*?)\]\]>",
        full_text_content,
        flags=re.DOTALL | re.IGNORECASE
    )
    if not cdata_blocks:
        # fallback: tenta usar tudo mesmo assim
        cdata_blocks = [full_text_content]

    # -------------------------------------------------
    # Estrutura intermedi√°ria
    # Cada bloco or√ßament√°rio detectado ficar√° assim:
    # {
    #   "orgao": "52000 - Minist√©rio da Defesa",
    #   "uo_code": "52931",
    #   "uo_name": "Fundo Naval",
    #   "tipo": "ACR√âSCIMO" / "REDU√á√ÉO" (ou None se n√£o detectamos),
    #   "acoes": [ { "acao": "6112 21GN", "desc": "...", "valor": 1906510 }, ... ],
    #   "totais": { "FISCAL": 5271675, "GERAL": ... }
    # }
    # -------------------------------------------------
    all_detected_blocks = []

    for blob in cdata_blocks:
        soup_blob = BeautifulSoup(blob, "html.parser")
        tables = soup_blob.find_all("table")
        if not tables:
            continue

        current_orgao = None
        current_uo_code = None
        current_uo_name = None
        current_tipo = None
        current_block = None

        def start_new_block():
            return {
                "orgao": current_orgao,
                "uo_code": current_uo_code,
                "uo_name": current_uo_name,
                "tipo": current_tipo,
                "acoes": [],
                "totais": {},
            }

        for table in tables:
            # transforma tabela em linhas limpas
            all_rows = []
            for tr in table.find_all("tr"):
                cols = [
                    _clean_text_local(td.get_text(" ", strip=True))
                    for td in tr.find_all(["td","th"])
                ]
                if any(col for col in cols):
                    all_rows.append(cols)

            for row in all_rows:
                joined = " ".join(row)

                # Detecta √ìRG√ÉO (ex: "√ìRG√ÉO: 52000 - Minist√©rio da Defesa")
                m_org = ORGAO_REGEX.search(joined)
                if m_org:
                    numero = m_org.group(1).strip()
                    nome = m_org.group(2).strip()
                    current_orgao = f"{numero} - {nome}"
                    current_uo_code = None
                    current_uo_name = None
                    current_tipo = None
                    current_block = None
                    continue

                # Detecta UNIDADE (ex: "UNIDADE: 52931 - Fundo Naval")
                m_uo = UO_REGEX.search(joined)
                if m_uo:
                    numero = m_uo.group(2).strip()
                    nome = m_uo.group(3).strip()
                    current_uo_code = numero
                    current_uo_name = nome
                    current_tipo = None
                    current_block = None
                    continue

                # Detecta in√≠cio de sub-bloco "(ACR√âSCIMO)" ou "(REDU√á√ÉO)"
                m_tipo = BLOCO_TIPO_REGEX.search(joined)
                if m_tipo:
                    tipo_raw = m_tipo.group(1).upper()
                    # Salva bloco anterior
                    if current_block:
                        all_detected_blocks.append(current_block)

                    if "ACR" in tipo_raw:
                        current_tipo = "ACR√âSCIMO"
                    else:
                        current_tipo = "REDU√á√ÉO"
                    current_block = start_new_block()
                    continue

                # Se estamos dentro de um bloco, tentar extrair conte√∫do
                if current_block:
                    # Poss√≠vel linha de a√ß√£o or√ßament√°ria com valor:
                    # primeira coluna = c√≥digo (ex: "6112 21GN" ou "6112 21GN 0001")
                    # √∫ltima coluna = valor num√©rico
                    possible_code = row[0].strip() if len(row) > 0 else ""
                    possible_val  = row[-1].strip() if len(row) > 0 else ""
                    has_code = re.match(r"^\d{3,4}", possible_code) is not None
                    has_money = (
                        re.search(r"\d", possible_val) is not None
                        and _parse_money(possible_val) > 0
                    )

                    if has_code and has_money and len(row) >= 2:
                        desc = row[1].strip()
                        norm_code = _canonicalize_action_code(possible_code)
                        current_block["acoes"].append({
                            "acao": norm_code,
                            "desc": desc,
                            "valor": _parse_money(possible_val),
                        })
                        continue

                    # Totais "TOTAL - FISCAL   5.271.675"
                    m_total = TOTAL_REGEX.search(joined)
                    if m_total and len(row) >= 2:
                        tipo_total = m_total.group(1).upper()
                        raw_val = row[-1]
                        current_block["totais"][tipo_total] = _parse_money(raw_val)
                        continue

        # fim das tabelas -> guarda √∫ltimo bloco aberto
        if current_block:
            all_detected_blocks.append(current_block)

    # -------------------------------------------------
    # 3. Filtrar apenas blocos Defesa/Marinha
    # -------------------------------------------------
    mb_blocks = []
    for b in all_detected_blocks:
        orgao_ok = (
            b["orgao"]
            and ("DEFESA" in b["orgao"].upper() or "52000" in b["orgao"])
        )
        uo_ok = (b["uo_code"] in MB_UOS)

        if orgao_ok or uo_ok:
            mb_blocks.append(b)

    if not mb_blocks:
        return (
            "Publica√ß√£o or√ßament√°ria do MPO potencialmente relevante, "
            "mas n√£o foi poss√≠vel extrair valores espec√≠ficos das UOs da Marinha/Defesa nos anexos."
        )

    # -------------------------------------------------
    # 4. Consolidar a√ß√µes repetidas
    #    (mesma a√ß√£o-base aparece v√°rias linhas '0001','0002' etc.)
    # -------------------------------------------------
    for b in mb_blocks:
        dedup: Dict[str, Dict[str, Any]] = {}
        for a in b["acoes"]:
            key = (a["acao"], a["desc"])
            if key not in dedup:
                dedup[key] = {
                    "acao": a["acao"],
                    "desc": a["desc"],
                    "valor": 0,
                }
            dedup[key]["valor"] += a["valor"]

        # agora tira itens id√™nticos demais tipo:
        #   "6112 21GN" vs "6112 21GN 0001"
        # a essa altura _canonicalize_action_code j√° transformou ambos pra "6112 21GN",
        # ent√£o eles j√° ca√≠ram juntos no mesmo key.
        b["acoes"] = list(dedup.values())

    # -------------------------------------------------
    # 5. Agrupar blocos por UO (UO code + nome amig√°vel)
    # -------------------------------------------------
    grouped = {}  # uo_key -> [blocos]
    for b in mb_blocks:
        if b["uo_code"] and b["uo_name"]:
            uo_key = f"{b['uo_code']} - {b['uo_name']}"
        elif b["orgao"]:
            uo_key = b["orgao"]
        else:
            uo_key = "Unidade n√£o identificada"
        grouped.setdefault(uo_key, []).append(b)

    # -------------------------------------------------
    # 6. Montar mensagem final
    # -------------------------------------------------
    out_lines = []

    if is_alteracao_fonte:
        out_lines.append(
            "Altera√ß√£o de fonte de recurso/IRP com impacto na Defesa/Marinha. "
            "Recursos foram realocados entre fontes internas; valores a seguir:"
        )
    else:
        out_lines.append(
            "Ato or√ßament√°rio do MPO com impacto na Defesa/Marinha. Dados extra√≠dos automaticamente:"
        )

    out_lines.append("")  # linha em branco

    for uo_key, blocos in grouped.items():
        # Se a UO existir na nossa tabela de nomes oficiais, usa o nome bonito
        nice_key = uo_key
        m_code = re.match(r"^(\d{5})", uo_key)
        if m_code:
            code = m_code.group(1)
            if code in MB_UOS:
                nice_key = f"{code} - {MB_UOS[code]}"

        out_lines.append(f"*{nice_key}*")

        # Junta totais por tipo (ACR√âSCIMO vs REDU√á√ÉO) dentro da mesma UO
        # e tamb√©m prepara lista de a√ß√µes
        for b in blocos:
            # decide o r√≥tulo
            if is_alteracao_fonte:
                # n√£o usar "Cancelamento (REDU√á√ÉO)" que soa negativo;
                # descreve genericamente ajuste interno:
                rotulo = "Ajuste interno de fonte"
            else:
                rotulo = (
                    "Suplementa√ß√£o (ACR√âSCIMO)"
                    if b["tipo"] == "ACR√âSCIMO"
                    else "Cancelamento (REDU√á√ÉO)"
                )

            total_fiscal = b["totais"].get("FISCAL", 0)
            total_geral = b["totais"].get("GERAL", 0)
            total_base = total_fiscal if total_fiscal else total_geral

            if total_base:
                val_fmt = f"R$ {total_base:,}".replace(",", ".")
                if is_alteracao_fonte:
                    out_lines.append(
                        f"  - {rotulo}: {val_fmt} (troca de fonte, n√£o aumento l√≠quido de gasto)"
                    )
                else:
                    out_lines.append(f"  - {rotulo}: {val_fmt}")
            else:
                out_lines.append(f"  - {rotulo}: valores por a√ß√£o abaixo")

            # listar at√© ~5 a√ß√µes mais relevantes
            for a in b["acoes"][:5]:
                val_fmt = f"R$ {a['valor']:,}".replace(",", ".")
                desc_curta = a["desc"]
                # deixar a descri√ß√£o mais curta tirando repeti√ß√µes "do Minist√©rio da Defesa" duplicadas?
                # vamos deixar por enquanto
                out_lines.append(f"    ‚Ä¢ {desc_curta} ‚Äî {val_fmt}")

        out_lines.append("")

    return "\n".join(out_lines).strip()
# =====================================================================================
# CLASSIFICA√á√ÉO INICIAL (SEM IA)
# =====================================================================================

def process_grouped_materia(
    main_article: BeautifulSoup,
    full_text_content: str,
    custom_keywords: List[str],
) -> Optional[Publicacao]:
    """
    1. Decide se a mat√©ria √© relevante.
    2. Gera reason inicial (sem IA ou pr√©-IA).
    3. Marca is_mpo_navy_hit pra proteger relev√¢ncia na IA.
    """

    organ = norm(main_article.get("artCategory", ""))
    organ_lower = organ.lower()

    # Ignorar conte√∫dos que s√£o claramente s√≥ FAB ou Ex√©rcito
    if (
        "comando da aeron√°utica" in organ_lower
        or "comando do ex√©rcito" in organ_lower
    ):
        return None

    section = (main_article.get("pubName", "") or "").upper()

    body = main_article.find("body")
    if not body:
        return None

    act_type = norm(
        body.find("Identifica").get_text(strip=True)
        if body.find("Identifica")
        else ""
    )
    if not act_type:
        return None

    summary = norm(
        body.find("Ementa").get_text(strip=True)
        if body.find("Ementa")
        else ""
    )

    display_text = norm(body.get_text(strip=True))

    # fallback pra ementa
    if not summary:
        match = re.search(
            r"EMENTA:(.*?)(Vistos|ACORDAM)",
            display_text,
            re.DOTALL | re.I,
        )
        if match:
            summary = norm(match.group(1))

    is_relevant = False
    reason = None
    search_content_lower = norm(full_text_content).lower()
    clean_text_for_ia = ""
    is_mpo_navy_hit_flag = False

    # ---------------------
    # SE√á√ÉO 1 (DO1)
    # ---------------------
    if "DO1" in section:
        is_mpo = MPO_ORG_STRING in organ_lower

        if is_mpo:
            # Checa se esta portaria toca UOs da MB
            found_navy_codes = [
                code for code in MPO_NAVY_TAGS
                if code.lower() in search_content_lower
            ]

            if found_navy_codes:
                is_relevant = True

                # heur√≠stica de impacto direto
                found_specific = [c for c in found_navy_codes if c != "52000"]
                found_defesa = "52000" in found_navy_codes
                if found_specific:
                    is_mpo_navy_hit_flag = True
                elif found_defesa and found_specific:
                    is_mpo_navy_hit_flag = True
                else:
                    is_mpo_navy_hit_flag = False

                summary_lower = summary.lower()

                gatilho_gnd = (
                    "grupo de natureza da despesa" in summary_lower
                    or "grupos de natureza da despesa" in summary_lower
                    or "gnd" in summary_lower
                    or "natureza da despesa" in summary_lower
                    or "altera parcialmente grupos" in summary_lower
                    or "adequa os grupos de natureza" in summary_lower
                    or "adequa os grupos de natureza da despesa" in summary_lower
                )

                gatilho_lme = (
                    "limites de movimenta√ß√£o e empenho" in summary_lower
                    or "limite de movimenta√ß√£o e empenho" in summary_lower
                    or "ajusta os limites de movimenta√ß√£o e empenho" in summary_lower
                    or "antecipa os limites de movimenta√ß√£o e empenho" in summary_lower
                    or "lme" in summary_lower
                )

                gatilho_fonte = (
                    "fonte de recursos" in summary_lower
                    or "fontes de recursos" in summary_lower
                    or "reclassifica√ß√£o de fonte" in summary_lower
                    or "altera a fonte" in summary_lower
                    or "modifica fontes de recursos" in summary_lower
                    or "altera√ß√£o de fonte" in summary_lower
                    or "identificador de resultado prim√°rio" in summary_lower
                )

                gatilho_credito = (
                    "abre cr√©dito suplementar" in summary_lower
                    or "cr√©dito suplementar" in summary_lower
                    or "abre aos or√ßamentos fiscal" in summary_lower
                    or "suplementa dota√ß√µes" in summary_lower
                    or "refor√ßo de dota√ß√µes" in summary_lower
                    or "refor√ßo de dota√ß√£o" in summary_lower
                    or "suplementa√ß√£o de cr√©dito" in summary_lower
                    or "suplementa√ß√£o de dota√ß√µes" in summary_lower
                    or "cr√©dito suplementar no valor de" in summary_lower
                )

                # NOVO: sempre tenta extrair valores reais pra MPO relevante
                if gatilho_gnd or gatilho_lme or gatilho_fonte or gatilho_credito:
                    reason = parse_mpo_budget_table(full_text_content)
                else:
                    reason = (
                        ANNOTATION_POSITIVE_GENERIC
                        or "Publica√ß√£o potencialmente relevante para a Marinha. Recomenda-se an√°lise detalhada."
                    )

            # √â MPO mas n√£o achou c√≥digos MB/Defesa
            elif any(bkw in search_content_lower for bkw in BUDGET_KEYWORDS_S1):
                is_relevant = True
                reason = (
                    ANNOTATION_NEGATIVE
                    or "Ato or√ßament√°rio do MPO, mas n√£o foi poss√≠vel confirmar impacto direto na Marinha."
                )

        else:
            # N√£o √© MPO, mas pode ter Marinha direta (EMA, DPC, DHN etc.)
            for kw in KEYWORDS_DIRECT_INTEREST_S1:
                if kw in search_content_lower:
                    is_relevant = True
                    reason = f"H√° men√ß√£o espec√≠fica √† TAG: '{kw}'."
                    break

    # ---------------------
    # SE√á√ÉO 2 (DO2) - pessoal
    # ---------------------
    elif "DO2" in section:
        soup_copy = BeautifulSoup(full_text_content, "lxml-xml")
        for tag in soup_copy.find_all("p", class_=["assina", "cargo"]):
            tag.decompose()

        clean_search_content_lower = norm(
            soup_copy.get_text(strip=True)
        ).lower()

        # 1) termos institucionais rastreados
        for term in TERMS_AND_ACRONYMS_S2:
            if term.lower() in clean_search_content_lower:
                is_relevant = True
                reason = f"Ato de pessoal (Se√ß√£o 2): men√ß√£o a '{term}'."
                break

        # 2) nome rastreado + verbo de a√ß√£o
        if not is_relevant:
            for name in NAMES_TO_TRACK:
                name_lower = name.lower()
                for match in re.finditer(name_lower, clean_search_content_lower):
                    start_pos = max(0, match.start() - 150)
                    ctx = clean_search_content_lower[start_pos: match.start()]
                    if any(verb in ctx for verb in PERSONNEL_ACTION_VERBS):
                        is_relevant = True
                        reason = (
                            f"Ato de pessoal (Se√ß√£o 2): men√ß√£o a '{name}' em contexto de a√ß√£o."
                        )
                        break
                if is_relevant:
                    break

    # ---------------------
    # Palavras-chave personalizadas
    # ---------------------
    found_custom_kw = None
    custom_reason_text = None
    if custom_keywords:
        for kw in custom_keywords:
            if kw and kw.lower() in search_content_lower:
                found_custom_kw = kw
                custom_reason_text = (
                    f"H√° men√ß√£o √† palavra-chave personalizada: '{kw}'."
                )
                break

    if found_custom_kw:
        is_relevant = True
        if reason and reason != ANNOTATION_NEGATIVE:
            reason = f"{reason}\n‚öì {custom_reason_text}"
        elif (not reason) or reason == ANNOTATION_NEGATIVE:
            reason = custom_reason_text

    # ---------------------
    # Monta Publicacao se relevante
    # ---------------------
    if is_relevant:
        soup_full_clean = BeautifulSoup(full_text_content, "lxml-xml")
        clean_text_for_ia = norm(soup_full_clean.get_text(strip=True))

        return Publicacao(
            organ=organ,
            type=act_type,
            summary=summary,
            raw=display_text,
            relevance_reason=reason,
            section=section,
            clean_text=clean_text_for_ia,
            is_mpo_navy_hit=is_mpo_navy_hit_flag,
        )

    return None

# =====================================================================================
# INLABS / DOWNLOAD ZIP
# =====================================================================================

async def inlabs_login_and_get_session() -> httpx.AsyncClient:
    if not INLABS_USER or not INLABS_PASS:
        raise HTTPException(
            status_code=500,
            detail="Config ausente: INLABS_USER e INLABS_PASS.",
        )

    client = httpx.AsyncClient(timeout=60, follow_redirects=True)

    # warm-up
    try:
        await client.get(INLABS_BASE)
    except Exception:
        pass

    r = await client.post(
        INLABS_LOGIN_URL,
        data={"email": INLABS_USER, "password": INLABS_PASS},
    )
    if r.status_code >= 400:
        await client.aclose()
        raise HTTPException(
            status_code=502,
            detail=f"Falha de login no INLABS: HTTP {r.status_code}",
        )

    return client


async def resolve_date_url(client: httpx.AsyncClient, date: str) -> str:
    """
    Depois do login, acha a pasta da data desejada e retorna URL base.
    """
    r = await client.get(INLABS_BASE)
    r.raise_for_status()

    soup = BeautifulSoup(r.text, "html.parser")

    cand_texts = [
        date,
        date.replace("-", "_"),
        date.replace("-", ""),
    ]

    for a in soup.find_all("a"):
        href = (a.get("href") or "").strip()
        txt = (a.get_text() or "").strip()
        hay = (txt + " " + href).lower()
        if any(c.lower() in hay for c in cand_texts):
            return urljoin(INLABS_BASE.rstrip("/") + "/", href.lstrip("/"))

    # fallback: tenta {BASE}/{date}/
    fallback_url = f"{INLABS_BASE.rstrip('/')}/{date}/"
    rr = await client.get(fallback_url)
    if rr.status_code == 200:
        return fallback_url

    raise HTTPException(
        status_code=404,
        detail=f"N√£o encontrei a pasta/listagem da data {date} ap√≥s login.",
    )


async def fetch_listing_html(client: httpx.AsyncClient, date: str) -> str:
    base_url = await resolve_date_url(client, date)
    r = await client.get(base_url)
    if r.status_code >= 400:
        raise HTTPException(
            status_code=502,
            detail=f"Falha ao abrir listagem {base_url}: HTTP {r.status_code}",
        )
    return r.text


def pick_zip_links_from_listing(
    html: str,
    base_url_for_rel: str,
    only_sections: List[str],
) -> List[str]:
    """
    Seleciona os .zip relevantes (DO1, DO2, etc.) naquela data.
    """
    soup = BeautifulSoup(html, "html.parser")
    links: List[str] = []

    wanted = set(s.upper() for s in only_sections) if only_sections else {"DO1"}

    for a in soup.find_all("a", href=True):
        href = a["href"]
        if href.lower().endswith(".zip"):
            label = (a.get_text() or href).upper()
            if any(sec in label for sec in wanted):
                links.append(urljoin(base_url_for_rel.rstrip("/") + "/", href))

    return sorted(list(set(links)))


async def download_zip(client: httpx.AsyncClient, url: str) -> bytes:
    r = await client.get(url)
    if r.status_code >= 400:
        raise HTTPException(
            status_code=502,
            detail=f"Falha ao baixar ZIP {url}: HTTP {r.status_code}",
        )
    return r.content


def extract_xml_from_zip(zip_bytes: bytes) -> List[bytes]:
    """
    L√™ um ZIP em mem√≥ria e retorna todos os XMLs (cada XML √© um peda√ßo de uma mat√©ria).
    """
    xml_blobs: List[bytes] = []

    with zipfile.ZipFile(io.BytesIO(zip_bytes)) as z:
        for name in z.namelist():
            if name.lower().endswith(".xml"):
                xml_blobs.append(z.read(name))

    return xml_blobs

# =====================================================================================
# /processar-inlabs (SEM IA)
# =====================================================================================

@app.post("/processar-inlabs", response_model=ProcessResponse)
async def processar_inlabs(
    data: str = Form(..., description="YYYY-MM-DD"),
    sections: Optional[str] = Form("DO1,DO2", description="Ex.: 'DO1,DO2,DO3'"),
    keywords_json: Optional[str] = Form(
        None,
        description='JSON lista de keywords. Ex: \'["amazul","prosub"]\'',
    ),
):
    """
    Pipeline 'r√°pida', sem IA.
    - Login no InLabs
    - Baixa ZIPs do dia e extrai XML
    - Agrupa fragmentos por idMateria
    - process_grouped_materia decide relev√¢ncia e reason
    - Gera WhatsApp final
    """

    secs = (
        [s.strip().upper() for s in sections.split(",") if s.strip()]
        if sections
        else ["DO1"]
    )

    # Keywords personalizadas
    custom_keywords: List[str] = []
    if keywords_json:
        try:
            keywords_list = json.loads(keywords_json)
            if isinstance(keywords_list, list):
                custom_keywords = [
                    str(k).strip().lower()
                    for k in keywords_list
                    if str(k).strip()
                ]
        except json.JSONDecodeError:
            pass

    client = await inlabs_login_and_get_session()
    try:
        listing_url = await resolve_date_url(client, data)
        html = await fetch_listing_html(client, data)
        zip_links = pick_zip_links_from_listing(html, listing_url, secs)
        if not zip_links:
            raise HTTPException(
                status_code=404,
                detail=f"N√£o encontrei ZIPs para a se√ß√£o '{', '.join(secs)}'.",
            )

        all_xml_blobs = []
        for zurl in zip_links:
            zb = await download_zip(client, zurl)
            all_xml_blobs.extend(extract_xml_from_zip(zb))

        # Agrupar por idMateria
        materias: Dict[str, Dict[str, Any]] = {}
        for blob in all_xml_blobs:
            try:
                soup = BeautifulSoup(blob, "lxml-xml")
                article = soup.find("article")
                if not article:
                    continue

                materia_id = article.get("idMateria")
                if not materia_id:
                    continue

                if materia_id not in materias:
                    materias[materia_id] = {
                        "main_article": None,
                        "full_text": "",
                    }

                materias[materia_id]["full_text"] += (
                    blob.decode("utf-8", errors="ignore") + "\n"
                )

                body = article.find("body")
                if (
                    body
                    and body.find("Identifica")
                    and body.find("Identifica").get_text(strip=True)
                ):
                    materias[materia_id]["main_article"] = article

            except Exception:
                continue

        pubs: List[Publicacao] = []

        for materia_id, content in materias.items():
            if content["main_article"]:
                publication = process_grouped_materia(
                    content["main_article"],
                    content["full_text"],
                    custom_keywords,
                )
                if publication:
                    pubs.append(publication)

        # Deduplicar publica√ß√µes parecidas
        seen: Set[str] = set()
        merged: List[Publicacao] = []
        for p in pubs:
            key = (
                (p.organ or "")
                + "||"
                + (p.type or "")
                + "||"
                + (p.summary or "")[:100]
            )
            if key not in seen:
                seen.add(key)
                merged.append(p)

        texto = monta_whatsapp(merged, data)

        return ProcessResponse(
            date=data,
            count=len(merged),
            publications=merged,
            whatsapp_text=texto,
        )

    finally:
        await client.aclose()

# =====================================================================================
# IA helper
# =====================================================================================

async def get_ai_analysis(
    clean_text: str,
    model: genai.GenerativeModel,
    prompt_template: str = GEMINI_MASTER_PROMPT,
) -> Optional[str]:
    """
    Chama Gemini pra gerar UMA frase curta de impacto.
    Retornos poss√≠veis:
      - string normal
      - "Erro na an√°lise de IA: ..." (erro recuper√°vel)
      - None (modelo n√£o quis responder)
    """

    try:
        prompt = f"{prompt_template}\n\n{clean_text}"

        response = await model.generate_content_async(prompt)

        try:
            analysis = norm(response.text)
            if analysis:
                return analysis
            else:
                # resposta vazia
                try:
                    finish_reason = response.prompt_feedback.finish_reason.name
                except Exception:
                    finish_reason = "desconhecido"
                print(f"Resposta da IA vazia. Raz√£o: {finish_reason}")
                return None

        except ValueError as e:
            # tipicamente bloqueio de seguran√ßa
            print(f"Bloco de IA (ValueError): {e}")
            return None
        except Exception as e_inner:
            print(f"Erro inesperado ao processar resposta da IA: {e_inner}")
            return "Erro processando resposta IA: " + str(e_inner)[:50]

    except Exception as e:
        print(f"Erro na API do Gemini: {e}")
        msg = str(e).lower()
        if "quota" in msg:
            return "Erro na an√°lise de IA: Cota de uso da API excedida."
        if "api_key" in msg:
            return "Erro na an√°lise de IA: Chave de API inv√°lida."
        return "Erro na an√°lise de IA: " + str(e)[:100]

# =====================================================================================
# /processar-inlabs-ia (COM IA)
# =====================================================================================

@app.post("/processar-inlabs-ia", response_model=ProcessResponse)
async def processar_inlabs_ia(
    data: str = Form(..., description="YYYY-MM-DD"),
    sections: Optional[str] = Form("DO1,DO2", description="Ex.: 'DO1,DO2,DO3'"),
    keywords_json: Optional[str] = Form(
        None, description="JSON string de keywords"
    ),
):
    """
    Pipeline com IA:
    - faz todo o fluxo de /processar-inlabs
    - depois chama Gemini pra uma frase curta por item
    - protege MPO com impacto direto na Marinha (is_mpo_navy_hit)
    """

    if not GEMINI_API_KEY:
        raise HTTPException(
            status_code=500,
            detail="A vari√°vel GEMINI_API_KEY n√£o est√° definida.",
        )

    try:
        model = genai.GenerativeModel("gemini-2.5-pro")
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Falha ao inicializar o modelo de IA: {e}",
        )

    secs = (
        [s.strip().upper() for s in sections.split(",") if s.strip()]
        if sections
        else ["DO1"]
    )

    custom_keywords: List[str] = []
    if keywords_json:
        try:
            keywords_list = json.loads(keywords_json)
            if isinstance(keywords_list, list):
                custom_keywords = [
                    str(k).strip().lower()
                    for k in keywords_list
                    if str(k).strip()
                ]
        except json.JSONDecodeError:
            pass

    client = await inlabs_login_and_get_session()
    pubs_filtradas: List[Publicacao] = []

    try:
        listing_url = await resolve_date_url(client, data)
        html = await fetch_listing_html(client, data)
        zip_links = pick_zip_links_from_listing(html, listing_url, secs)
        if not zip_links:
            raise HTTPException(
                status_code=404,
                detail=f"N√£o encontrei ZIPs para a se√ß√£o '{', '.join(secs)}'.",
            )

        all_xml_blobs = []
        for zurl in zip_links:
            zb = await download_zip(client, zurl)
            all_xml_blobs.extend(extract_xml_from_zip(zb))

        materias: Dict[str, Dict[str, Any]] = {}
        for blob in all_xml_blobs:
            try:
                soup = BeautifulSoup(blob, "lxml-xml")
                article = soup.find("article")
                if not article:
                    continue

                materia_id = article.get("idMateria")
                if not materia_id:
                    continue

                if materia_id not in materias:
                    materias[materia_id] = {
                        "main_article": None,
                        "full_text": "",
                    }

                materias[materia_id]["full_text"] += (
                    blob.decode("utf-8", errors="ignore") + "\n"
                )

                body = article.find("body")
                if (
                    body
                    and body.find("Identifica")
                    and body.find("Identifica").get_text(strip=True)
                ):
                    materias[materia_id]["main_article"] = article

            except Exception:
                continue

        # Est√°gio 1 (regra fixa)
        for materia_id, content in materias.items():
            if content["main_article"]:
                publication = process_grouped_materia(
                    content["main_article"],
                    content["full_text"],
                    custom_keywords,
                )
                if publication:
                    pubs_filtradas.append(publication)

        # Dedup
        seen: Set[str] = set()
        merged_pubs: List[Publicacao] = []
        for p in pubs_filtradas:
            key = (
                (p.organ or "")
                + "||"
                + (p.type or "")
                + "||"
                + (p.summary or "")[:100]
            )
            if key not in seen:
                seen.add(key)
                merged_pubs.append(p)

        # Est√°gio 2 (IA)
        tasks = []
        for p in merged_pubs:
            prompt_to_use = GEMINI_MASTER_PROMPT
            if p.is_mpo_navy_hit:
                prompt_to_use = GEMINI_MPO_PROMPT

            if p.clean_text:
                tasks.append(get_ai_analysis(p.clean_text, model, prompt_to_use))
            else:
                tasks.append(
                    get_ai_analysis(
                        p.relevance_reason or "Texto n√£o dispon√≠vel",
                        model,
                        prompt_to_use,
                    )
                )

        ai_results = await asyncio.gather(*tasks, return_exceptions=True)

        pubs_finais: List[Publicacao] = []

        for p, ai_out in zip(merged_pubs, ai_results):
            if isinstance(ai_out, Exception):
                p.relevance_reason = f"Erro GRAVE na an√°lise de IA: {ai_out}"
                pubs_finais.append(p)
                continue

            if ai_out is None:
                # IA ficou muda, mant√©m reason original (que j√° pode ter vindo do parser MPO)
                pubs_finais.append(p)
                continue

            if isinstance(ai_out, str):
                lower_ai = ai_out.lower()

                if ai_out.startswith("Erro na an√°lise de IA:"):
                    p.relevance_reason = ai_out
                    pubs_finais.append(p)
                    continue

                # IA disse "sem impacto direto"
                if "sem impacto direto" in lower_ai:
                    if p.is_mpo_navy_hit:
                        # a IA quis minimizar mas a gente j√° sabe que impacta MB
                        p.relevance_reason = "‚ö†Ô∏è IA ignorou impacto MPO: " + ai_out
                        pubs_finais.append(p)
                    elif MPO_ORG_STRING in (p.organ or "").lower():
                        # √© MPO mas sem hit direto -> ok aceitar o 'sem impacto direto'
                        p.relevance_reason = ai_out
                        pubs_finais.append(p)
                    else:
                        # se n√£o √© MPO e IA falou que √© irrelevante -> filtra fora
                        pass
                    continue

                # caso feliz: IA deu uma frase √∫til
                p.relevance_reason = ai_out
                pubs_finais.append(p)
                continue

            # fallback
            pubs_finais.append(p)

        texto = monta_whatsapp(pubs_finais, data)

        return ProcessResponse(
            date=data,
            count=len(pubs_finais),
            publications=pubs_finais,
            whatsapp_text=texto,
        )

    finally:
        await client.aclose()

# =====================================================================================
# HEALTHCHECK
# =====================================================================================

@app.get("/")
async def root():
    return {"status": "ok", "ts": datetime.now().isoformat()}

# =====================================================================================
# TESTE IA
# =====================================================================================

@app.get("/test-ia")
async def test_ia_endpoint():
    if not GEMINI_API_KEY:
        raise HTTPException(
            status_code=500,
            detail="GEMINI_API_KEY n√£o configurada.",
        )

    try:
        model = genai.GenerativeModel("gemini-2.5-pro")
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Falha ao inicializar modelo IA: {e}",
        )

    test_prompt = "Qual a capital do Brasil?"
    print(f"[TESTE IA] Pergunta: {test_prompt}")

    try:
        response = await model.generate_content_async(test_prompt)
        try:
            analysis = norm(response.text)
            if analysis:
                print(f"[TESTE IA] OK: {analysis}")
                return {"result": f"Teste OK! IA respondeu: '{analysis}'"}
            else:
                print("[TESTE IA] Falhou: resposta vazia")
                return {"result": "Teste FALHOU. Resposta vazia da IA."}
        except ValueError as e:
            print(f"[TESTE IA] Falhou (ValueError): {e}")
            return {"result": f"Teste FALHOU. A IA bloqueou a resposta: {e}"}
        except Exception as e_inner:
            print(f"[TESTE IA] Falhou (parse): {e_inner}")
            return {
                "result": "Teste FALHOU. Erro processando resposta IA: "
                + str(e_inner)[:50]
            }

    except Exception as e:
        print(f"[TESTE IA] Falhou (API): {e}")
        msg = str(e).lower()
        detail = str(e)[:100]
        if "quota" in msg:
            detail = "Cota de uso da API excedida."
        elif "api_key" in msg:
            detail = "Chave de API inv√°lida."
        raise HTTPException(
            status_code=500,
            detail=f"Teste FALHOU. Erro na chamada da API: {detail}",
        )

# Nome do arquivo: dou_pdf_reader.py
# Vers√£o: 1.0 (PDF H√≠brido + Prompt Especialista)

import fitz  # PyMuPDF
import httpx
import os
import re
import asyncio
from datetime import datetime
from typing import List, Dict, Optional
import google.generativeai as genai

# --- SEU PROMPT ESPECIALISTA (Id√™ntico ao fornecido) ---
PROMPT_ESPECIALISTA_MPO = """
### ROLE
Voc√™ √© um Especialista em An√°lise Or√ßament√°ria e Defesa (Marinha do Brasil).

### DIRETRIZES DE BUSCA DE ENTIDADES (UOs)
Busque especificamente pelas UGs:
- "52131" (Comando da Marinha), "52133" (SECIRM), "52232" (CCCPM), "52233" (AMAZUL)
- "52931" (Fundo Naval), "52932" (Fundo Ensino), "52000" (MD - Apenas p/ Movimenta√ß√£o)

### REGRA DE EXAUSTIVIDADE
Liste TODAS as Portarias do MPO e MF encontradas nesta p√°gina.
- Se citar UOs da MB -> Tipos 1, 2, 3 ou 4.
- Se N√ÉO citar UOs da MB -> Tipo 5 (Sem Impacto).

### REGRAS DE CLASSIFICA√á√ÉO (Resumo)
TIPO 1: Cr√©dito Suplementar (Com Impacto MB)
TIPO 2: Movimenta√ß√£o e Empenho (Com Impacto MD)
TIPO 3: Altera√ß√£o de GND (Com Impacto MB)
TIPO 4: Modifica√ß√£o de Fontes (Com Impacto MB)
TIPO 5: Sem Impacto (Gen√©rico MPO/MF)

### FORMATO DE SA√çDA (Rigoroso)
Para cada ato encontrado, gere a sa√≠da exata abaixo (sem markdown json, apenas o texto):

‚ñ∂Ô∏è [√ìrg√£o Emissor]
üìå [NOME DA PORTARIA]
[Resumo breve]
‚öì [An√°lise conforme Tipo]
"""

# Prompt mais simples para capturas gerais (Licita√ß√µes, Avisos, etc.)
PROMPT_GERAL_MB = """
Voc√™ √© um analista da Marinha. Encontrei men√ß√µes √† Marinha/Defesa neste texto.
Fa√ßa um resumo de 1 frase para relat√≥rio WhatsApp.
Comece com: "‚ñ∂Ô∏è [√ìrg√£o] - [Tipo do Ato]"
Termine com: "‚öì [Impacto/Resumo]"
"""

# --- CONFIGURA√á√ÉO ---
IN_GOV_URL = "https://www.in.gov.br/leitura-jornal"
DOWNLOAD_DIR = "/tmp"  # No Render, usar /tmp

async def get_pdf_link_for_date(date_str: str, section: str = "do1") -> Optional[str]:
    """
    Busca o link do PDF completo da se√ß√£o no in.gov.br
    date_str: YYYY-MM-DD
    """
    dt = datetime.strptime(date_str, "%Y-%m-%d")
    date_formatted = dt.strftime("%d-%m-%Y")
    
    params = {"data": date_formatted, "secao": section}
    
    async with httpx.AsyncClient() as client:
        # Primeiro acessa a p√°gina de leitura para pegar o JSON de configura√ß√£o interna
        # Nota: A URL real do PDF segue um padr√£o, vamos tentar montar direto primeiro, 
        # se falhar, precisar√≠amos de um scraper mais complexo (Selenium/Soup), 
        # mas geralmente o padr√£o √©:
        # https://ens-cdn.in.gov.br/imprensa/jornal/{YYYY}/{MM}/{DD}/{SECAO}/pdf/jornal-{YYYY}-{MM}-{DD}-{SECAO}.pdf
        # Vamos tentar construir o link direto primeiro (√© mais r√°pido).
        
        base_cdn = "https://ens-cdn.in.gov.br/imprensa/jornal"
        ano, mes, dia = date_str.split("-")
        
        # O nome do arquivo pode variar (ex: jornal-2025-01-01-do1.pdf ou principal.pdf)
        # Vamos tentar o padr√£o mais comum do CDN
        url_candidate = f"{base_cdn}/{ano}/{mes}/{dia}/{section}/pdf/jornal-{ano}-{mes}-{dia}-{section}.pdf"
        
        try:
            head = await client.head(url_candidate)
            if head.status_code == 200:
                return url_candidate
        except:
            pass
            
        return None

async def download_pdf(url: str, filename: str) -> str:
    path = os.path.join(DOWNLOAD_DIR, filename)
    async with httpx.AsyncClient(timeout=60) as client:
        resp = await client.get(url)
        with open(path, "wb") as f:
            f.write(resp.content)
    return path

def extract_text_from_page(page) -> str:
    """Extrai texto preservando um pouco do layout f√≠sico"""
    return page.get_text("text")

async def analyze_pdf_content(pdf_path: str, model) -> List[Dict]:
    """
    L√≥gica H√≠brida:
    1. Abre PDF.
    2. Varre p√°ginas.
    3. Filtra p√°ginas de interesse (MPO/MF ou Keywords MB).
    4. Envia para Gemini.
    """
    results = []
    doc = fitz.open(pdf_path)
    
    print(f"üìÑ PDF carregado. Total p√°ginas: {len(doc)}")
    
    # Keywords para gatilho R√ÅPIDO (sem gastar token de IA)
    kw_mpo = ["minist√©rio do planejamento", "minist√©rio da fazenda", "secretaria do or√ßamento", "tesouro nacional"]
    kw_mb = ["comando da marinha", "fundo naval", "prosub", "nuclear", "tamandar√©", "emgepron", "amazul", "secirm"]
    
    tasks = []
    
    for i, page in enumerate(doc):
        text = extract_text_from_page(page).lower()
        
        # L√≥gica 1: √â MPO ou Fazenda? (Prioridade Alta - Prompt Especialista)
        is_mpo = any(k in text for k in kw_mpo) and ("portaria" in text or "decreto" in text)
        
        # L√≥gica 2: √â men√ß√£o √† Marinha (Geral)?
        is_mb = any(k in text for k in kw_mb)
        
        if is_mpo:
            # Envia p√°gina para Gemini com Prompt Especialista
            raw_text = page.get_text() # Pega texto original (case sensitive)
            tasks.append(run_gemini_analysis(raw_text, model, PROMPT_ESPECIALISTA_MPO, i+1, "MPO"))
            
        elif is_mb:
            # Envia p√°gina para Gemini com Prompt Resumo
            raw_text = page.get_text()
            tasks.append(run_gemini_analysis(raw_text, model, PROMPT_GERAL_MB, i+1, "GERAL"))
            
    # Executa em paralelo (cuidado com Rate Limit do Gemini, talvez precise de sem√°foro)
    # Vamos processar em lotes de 5 para n√£o estourar
    chunk_size = 5
    for i in range(0, len(tasks), chunk_size):
        chunk = tasks[i:i + chunk_size]
        chunk_results = await asyncio.gather(*chunk)
        for res in chunk_results:
            if res:
                results.append(res)
                
    doc.close()
    return results

async def run_gemini_analysis(text: str, model, prompt_template: str, page_num: int, context_type: str) -> Optional[Dict]:
    try:
        full_prompt = f"{prompt_template}\n\n--- TEXTO DA P√ÅGINA {page_num} DO DOU ---\n{text[:10000]}"
        
        # Gera resposta
        response = await model.generate_content_async(full_prompt)
        analysis = response.text.strip()
        
        # Se for MPO, filtramos "Sem impacto" se quisermos limpar o output
        if context_type == "MPO" and "Sem impacto para a Marinha" in analysis and "TIPO 5" in analysis:
             # Opcional: Se quiser ignorar os "Sem impacto", retorne None aqui.
             # Mas seu prompt pede para listar, ent√£o vamos manter.
             pass

        # Cria objeto estruturado para o Frontend
        # O frontend espera: organ, type, summary, relevance_reason
        
        # Tenta extrair o √ìrg√£o e T√≠tulo da resposta da IA para ficar bonitinho no Card
        organ = "DOU (IA)"
        title = f"P√°gina {page_num}"
        
        # Parse simples da sa√≠da padronizada
        if "‚ñ∂Ô∏è" in analysis:
            lines = analysis.split("\n")
            for line in lines:
                if "‚ñ∂Ô∏è" in line: organ = line.replace("‚ñ∂Ô∏è", "").strip()
                if "üìå" in line: title = line.replace("üìå", "").strip()
                break
        
        return {
            "organ": organ,
            "type": title,
            "summary": analysis, # O texto formatado vai aqui
            "relevance_reason": f"An√°lise IA (P√°g {page_num}) - {context_type}",
            "section": "DO1",
            "clean_text": text,
            "is_mpo_navy_hit": (context_type == "MPO")
        }

    except Exception as e:
        print(f"Erro Gemini P√°g {page_num}: {e}")
        return None
